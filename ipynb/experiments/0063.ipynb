{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data and Model Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'exp_063'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "codebase = '../../'\n",
    "sys.path.append(codebase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataflow.vg_graph_loader_3 import VGGraphLoader\n",
    "from src.dataflow.graph_batcher_2_rpn import GraphBatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.tensorflow.models.vsp_model_001_abl_01 import Model\n",
    "from src.tensorflow.engine.trainer_3 import Trainer\n",
    "from src.tensorflow.engine.util import deploy, load_params\n",
    "from src.util.util import pickle_save, pickle_load\n",
    "from src.eval.sgg_evaluator_03 import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(1224)\n",
    "np.random.seed(1225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl = VGGraphLoader(\n",
    "    os.path.join(codebase, 'metadata', 'VG', 'prep', 'hanwang', 'sg.pkl'),\n",
    "    os.path.join(codebase, 'metadata', 'VG', 'prep', 'hanwang', 'class_embs.pkl'),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids, train_idx, test_idx = pickle_load(os.path.join(codebase, 'metadata', 'VG', 'prep', 'hanwang', 'split.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(train_idx)\n",
    "val_idx = train_idx[:1000]\n",
    "train_idx = train_idx[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals = pickle_load(os.path.join(codebase, 'data', 'VG', 'xfeat_proposals', 'iresnet_oi_lowprop', 'coords.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = GraphBatcher(\n",
    "    gl, 32, proposals,\n",
    "    os.path.join(codebase, 'data', 'VG', 'xfeat_proposals', 'iresnet_oi_lowprop', 'feats_float32_20x1536.lmdb'), \n",
    "    dim_feats=1536,\n",
    "    seed=1236, \n",
    ")\n",
    "batcher.set_subset(train_idx)\n",
    "batcher.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher_val = GraphBatcher(\n",
    "    gl, 32, proposals,\n",
    "    os.path.join(codebase, 'data', 'VG', 'xfeat_proposals', 'iresnet_oi_lowprop', 'feats_float32_20x1536.lmdb'), \n",
    "    dim_feats=1536,\n",
    "    seed=1237, \n",
    ")\n",
    "batcher_val.set_subset(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../../src/tensorflow/models/vsp_model_001_abl_01.py:94: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/alireza/home_at_filer2/tools/anaconda3/envs/py3tf2/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From ../../src/tensorflow/util/util.py:15: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From ../../src/tensorflow/util/util.py:17: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From ../../src/tensorflow/models/vsp_model_001_abl_01.py:466: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "WARNING:tensorflow:From /home/alireza/home_at_filer2/tools/anaconda3/envs/py3tf2/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model = Model(   \n",
    "    dim_att_head_role_ent=[1024, 1024], \n",
    "    dim_att_head_role_pred=[1024, 1024],\n",
    "    role_edge_mode='full_soft',\n",
    "    stop_grad_role_edge=True,\n",
    "    \n",
    "    dim_state_ent=1024,\n",
    "    dim_state_pred=1024,\n",
    "    dim_emb_head_ent=[300],\n",
    "    dim_conf_head_ent=[],\n",
    "    dim_conf_head_pred=[],\n",
    "    dim_emb_head_pred=[300],\n",
    "    dim_init_head_ent=[1024],\n",
    "\n",
    "    dim_message_send_head_pred2ent=[1024, 1024],\n",
    "    dim_message_pool_head_pred2ent=[1024, 1024],\n",
    "    dim_message_receive_head_pred2ent=[1024, 1024],    \n",
    "    dim_message_send_head_ent2pred=[1024, 1024],\n",
    "    dim_message_pool_head_ent2pred=[1024, 1024],\n",
    "    dim_message_receive_head_ent2pred=[1024, 1024],\n",
    "    \n",
    "    num_mp_iter=3,     \n",
    "    num_proposals=None,\n",
    "\n",
    "    heat_role=1.0,\n",
    "    heat_emb_mil=1.0,\n",
    "    null_att_logit=0.0,\n",
    "        \n",
    "    num_align_iter=3,\n",
    "    alignment_order='best',\n",
    "    default_act_fn_name='leaky_relu',\n",
    "    optimizer_type_generator=tf.train.AdamOptimizer,\n",
    "    \n",
    "    max_num_pred=100,\n",
    "    dim_init_head_pred=[],\n",
    "    init_state_type_pred='trainable',\n",
    "    \n",
    "    dim_proposal_feat=1536,\n",
    "    emb_dict_ent=gl.noun_emb_dict,\n",
    "    emb_dict_pred=gl.pred_emb_dict,    \n",
    "    #image_size=448,\n",
    "    #num_channels=3,\n",
    "    debugging=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "#sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True)))\n",
    "#sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.5)))\n",
    "sess = tf.Session()\n",
    "sess.run(tf.no_op())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evaluator = Evaluator({        \n",
    "    'graph_loader': gl,\n",
    "    'proposals': proposals,\n",
    "    'num_proposals': 20,\n",
    "    'filter_nonoverlap': True\n",
    "})\n",
    "val_evaluator = Evaluator({        \n",
    "    'graph_loader': gl,\n",
    "    'proposals': proposals,\n",
    "    'num_proposals': 20,\n",
    "    'filter_nonoverlap': True\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model, sess, batcher, batcher_val, train_evaluator, val_evaluator,\n",
    "    logdir=os.path.join(codebase, 'log', 'tfsummary', exp_name), \n",
    "    modeldir=os.path.join(codebase, 'checkpoint', exp_name),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000: loss = 5.159999847412109 (3016.908 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.408, 'PerImagePredMR': 0.941, 'PerImageOneHopMP_at100_iou_0.5': 0.001, 'PerImageOneHopMR_at100_iou_0.5': 0.009, 'PerImageOneHopMP_at50_iou_0.5': 0.002, 'PerImageOneHopMR_at50_iou_0.5': 0.008, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.013, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.072, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.02, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.06}\n",
      "Validation Results: {'PerImagePredMP': 0.404, 'PerImagePredMR': 0.928, 'PerImageOneHopMP_at100_iou_0.5': 0.001, 'PerImageOneHopMR_at100_iou_0.5': 0.01, 'PerImageOneHopMP_at50_iou_0.5': 0.002, 'PerImageOneHopMR_at50_iou_0.5': 0.009, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.017, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.083, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.025, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.073}\n",
      "Step 2000: loss = 5.882999897003174 (5971.854 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.398, 'PerImagePredMR': 0.945, 'PerImageOneHopMP_at100_iou_0.5': 0.001, 'PerImageOneHopMR_at100_iou_0.5': 0.006, 'PerImageOneHopMP_at50_iou_0.5': 0.001, 'PerImageOneHopMR_at50_iou_0.5': 0.005, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.015, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.068, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.021, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.055}\n",
      "Validation Results: {'PerImagePredMP': 0.394, 'PerImagePredMR': 0.934, 'PerImageOneHopMP_at100_iou_0.5': 0.001, 'PerImageOneHopMR_at100_iou_0.5': 0.007, 'PerImageOneHopMP_at50_iou_0.5': 0.001, 'PerImageOneHopMR_at50_iou_0.5': 0.006, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.012, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.068, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.018, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.056}\n",
      "Step 3000: loss = 4.978000164031982 (8922.217 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.425, 'PerImagePredMR': 0.938, 'PerImageOneHopMP_at100_iou_0.5': 0.001, 'PerImageOneHopMR_at100_iou_0.5': 0.009, 'PerImageOneHopMP_at50_iou_0.5': 0.002, 'PerImageOneHopMR_at50_iou_0.5': 0.008, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.019, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.091, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.028, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.074}\n",
      "Validation Results: {'PerImagePredMP': 0.431, 'PerImagePredMR': 0.936, 'PerImageOneHopMP_at100_iou_0.5': 0.002, 'PerImageOneHopMR_at100_iou_0.5': 0.011, 'PerImageOneHopMP_at50_iou_0.5': 0.003, 'PerImageOneHopMR_at50_iou_0.5': 0.01, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.02, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.091, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.032, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.08}\n",
      "Step 4000: loss = 4.761000156402588 (11829.925 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.44, 'PerImagePredMR': 0.932, 'PerImageOneHopMP_at100_iou_0.5': 0.002, 'PerImageOneHopMR_at100_iou_0.5': 0.012, 'PerImageOneHopMP_at50_iou_0.5': 0.003, 'PerImageOneHopMR_at50_iou_0.5': 0.01, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.017, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.092, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.025, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.079}\n",
      "Validation Results: {'PerImagePredMP': 0.476, 'PerImagePredMR': 0.92, 'PerImageOneHopMP_at100_iou_0.5': 0.002, 'PerImageOneHopMR_at100_iou_0.5': 0.016, 'PerImageOneHopMP_at50_iou_0.5': 0.003, 'PerImageOneHopMR_at50_iou_0.5': 0.014, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.021, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.114, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.03, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.095}\n",
      "Step 5000: loss = 4.954999923706055 (14719.707 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.429, 'PerImagePredMR': 0.939, 'PerImageOneHopMP_at100_iou_0.5': 0.002, 'PerImageOneHopMR_at100_iou_0.5': 0.012, 'PerImageOneHopMP_at50_iou_0.5': 0.003, 'PerImageOneHopMR_at50_iou_0.5': 0.009, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.02, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.096, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.031, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.081}\n",
      "Validation Results: {'PerImagePredMP': 0.424, 'PerImagePredMR': 0.936, 'PerImageOneHopMP_at100_iou_0.5': 0.002, 'PerImageOneHopMR_at100_iou_0.5': 0.012, 'PerImageOneHopMP_at50_iou_0.5': 0.002, 'PerImageOneHopMR_at50_iou_0.5': 0.01, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.018, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.104, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.026, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.083}\n",
      "Step 6000: loss = 4.896999835968018 (17564.395 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.427, 'PerImagePredMR': 0.942, 'PerImageOneHopMP_at100_iou_0.5': 0.002, 'PerImageOneHopMR_at100_iou_0.5': 0.013, 'PerImageOneHopMP_at50_iou_0.5': 0.003, 'PerImageOneHopMR_at50_iou_0.5': 0.011, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.02, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.095, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.031, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.079}\n",
      "Validation Results: {'PerImagePredMP': 0.426, 'PerImagePredMR': 0.939, 'PerImageOneHopMP_at100_iou_0.5': 0.002, 'PerImageOneHopMR_at100_iou_0.5': 0.015, 'PerImageOneHopMP_at50_iou_0.5': 0.003, 'PerImageOneHopMR_at50_iou_0.5': 0.013, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.025, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.105, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.036, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.085}\n",
      "Step 7000: loss = 4.820000171661377 (20467.488 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.46, 'PerImagePredMR': 0.934, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.018, 'PerImageOneHopMP_at50_iou_0.5': 0.004, 'PerImageOneHopMR_at50_iou_0.5': 0.015, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.023, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.119, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.033, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.1}\n",
      "Validation Results: {'PerImagePredMP': 0.461, 'PerImagePredMR': 0.921, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.02, 'PerImageOneHopMP_at50_iou_0.5': 0.005, 'PerImageOneHopMR_at50_iou_0.5': 0.017, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.022, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.122, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.034, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.099}\n",
      "Step 8000: loss = 4.879000186920166 (23501.907 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.502, 'PerImagePredMR': 0.91, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.022, 'PerImageOneHopMP_at50_iou_0.5': 0.005, 'PerImageOneHopMR_at50_iou_0.5': 0.02, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.022, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.13, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.035, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.111}\n",
      "Validation Results: {'PerImagePredMP': 0.502, 'PerImagePredMR': 0.902, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.022, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.019, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.025, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.138, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.038, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.119}\n",
      "Step 9000: loss = 4.732999801635742 (26569.365 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.514, 'PerImagePredMR': 0.907, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.022, 'PerImageOneHopMP_at50_iou_0.5': 0.005, 'PerImageOneHopMR_at50_iou_0.5': 0.019, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.024, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.142, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.037, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.122}\n",
      "Validation Results: {'PerImagePredMP': 0.536, 'PerImagePredMR': 0.891, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.022, 'PerImageOneHopMP_at50_iou_0.5': 0.005, 'PerImageOneHopMR_at50_iou_0.5': 0.018, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.025, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.144, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.04, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.126}\n",
      "Step 10000: loss = 4.677000045776367 (29691.152 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.503, 'PerImagePredMR': 0.906, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.023, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.02, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.025, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.15, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.04, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.128}\n",
      "Validation Results: {'PerImagePredMP': 0.485, 'PerImagePredMR': 0.907, 'PerImageOneHopMP_at100_iou_0.5': 0.002, 'PerImageOneHopMR_at100_iou_0.5': 0.018, 'PerImageOneHopMP_at50_iou_0.5': 0.004, 'PerImageOneHopMR_at50_iou_0.5': 0.016, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.021, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.135, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.033, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.117}\n",
      "Step 11000: loss = 4.202000141143799 (32746.955 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.518, 'PerImagePredMR': 0.904, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.02, 'PerImageOneHopMP_at50_iou_0.5': 0.004, 'PerImageOneHopMR_at50_iou_0.5': 0.017, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.023, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.147, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.037, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.125}\n",
      "Validation Results: {'PerImagePredMP': 0.522, 'PerImagePredMR': 0.891, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.023, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.02, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.025, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.155, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.04, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.135}\n",
      "Step 13000: loss = 4.9629998207092285 (38966.125 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.51, 'PerImagePredMR': 0.902, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.023, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.021, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.025, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.159, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.04, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.133}\n",
      "Validation Results: {'PerImagePredMP': 0.549, 'PerImagePredMR': 0.893, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.017, 'PerImageOneHopMP_at50_iou_0.5': 0.005, 'PerImageOneHopMR_at50_iou_0.5': 0.015, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.027, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.156, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.043, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.131}\n",
      "Step 14000: loss = 4.061999797821045 (42053.977 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.517, 'PerImagePredMR': 0.904, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.024, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.021, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.028, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.172, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.045, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.15}\n",
      "Validation Results: {'PerImagePredMP': 0.533, 'PerImagePredMR': 0.901, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.026, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.023, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.028, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.159, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.045, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.139}\n",
      "Step 15000: loss = 4.820000171661377 (45135.116 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.525, 'PerImagePredMR': 0.904, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.025, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.021, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.025, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.155, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.04, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.131}\n",
      "Validation Results: {'PerImagePredMP': 0.517, 'PerImagePredMR': 0.906, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.025, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.023, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.027, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.166, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.044, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.144}\n",
      "Step 16000: loss = 4.209000110626221 (48213.935 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.524, 'PerImagePredMR': 0.903, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.022, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.019, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.026, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.151, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.041, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.131}\n",
      "Validation Results: {'PerImagePredMP': 0.518, 'PerImagePredMR': 0.899, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.024, 'PerImageOneHopMP_at50_iou_0.5': 0.005, 'PerImageOneHopMR_at50_iou_0.5': 0.021, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.028, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.168, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.043, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.143}\n",
      "Step 17000: loss = 4.275000095367432 (51312.594 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.515, 'PerImagePredMR': 0.914, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.022, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.019, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.026, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.164, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.042, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.142}\n",
      "Validation Results: {'PerImagePredMP': 0.521, 'PerImagePredMR': 0.9, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.023, 'PerImageOneHopMP_at50_iou_0.5': 0.005, 'PerImageOneHopMR_at50_iou_0.5': 0.02, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.028, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.167, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.044, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.142}\n",
      "Step 18000: loss = 4.011000156402588 (54369.867 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.511, 'PerImagePredMR': 0.914, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.024, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.021, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.027, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.169, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.044, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.146}\n",
      "Validation Results: {'PerImagePredMP': 0.526, 'PerImagePredMR': 0.898, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.022, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.021, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.026, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.166, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.041, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.141}\n",
      "Step 19000: loss = 3.9839999675750732 (57453.000 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.504, 'PerImagePredMR': 0.915, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.022, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.02, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.027, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.165, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.044, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.141}\n",
      "Validation Results: {'PerImagePredMP': 0.502, 'PerImagePredMR': 0.903, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.022, 'PerImageOneHopMP_at50_iou_0.5': 0.004, 'PerImageOneHopMR_at50_iou_0.5': 0.019, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.026, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.168, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.043, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.144}\n",
      "Step 20000: loss = 4.5980000495910645 (60461.120 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.518, 'PerImagePredMR': 0.911, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.021, 'PerImageOneHopMP_at50_iou_0.5': 0.005, 'PerImageOneHopMR_at50_iou_0.5': 0.018, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.027, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.166, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.043, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.144}\n",
      "Validation Results: {'PerImagePredMP': 0.513, 'PerImagePredMR': 0.903, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.027, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.024, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.03, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.18, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.048, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.153}\n",
      "Step 21000: loss = 4.480000019073486 (63448.572 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.516, 'PerImagePredMR': 0.91, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.022, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.019, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.028, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.165, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.044, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.139}\n",
      "Validation Results: {'PerImagePredMP': 0.529, 'PerImagePredMR': 0.899, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.026, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.021, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.031, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.178, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.048, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.149}\n",
      "Step 22000: loss = 4.125999927520752 (66373.996 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.516, 'PerImagePredMR': 0.914, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.023, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.02, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.028, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.172, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.045, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.147}\n",
      "Validation Results: {'PerImagePredMP': 0.514, 'PerImagePredMR': 0.906, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.025, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.022, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.028, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.172, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.046, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.15}\n",
      "Step 23000: loss = 4.366000175476074 (69276.098 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.512, 'PerImagePredMR': 0.914, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.023, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.021, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.029, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.175, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.048, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.151}\n",
      "Validation Results: {'PerImagePredMP': 0.508, 'PerImagePredMR': 0.898, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.024, 'PerImageOneHopMP_at50_iou_0.5': 0.005, 'PerImageOneHopMR_at50_iou_0.5': 0.02, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.029, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.173, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.046, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.146}\n",
      "Step 24000: loss = 4.361999988555908 (72212.126 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.511, 'PerImagePredMR': 0.917, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.023, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.021, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.028, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.173, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.043, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.145}\n",
      "Validation Results: {'PerImagePredMP': 0.524, 'PerImagePredMR': 0.899, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.022, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.02, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.028, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.157, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.045, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.136}\n",
      "Step 25000: loss = 3.9609999656677246 (75112.885 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.512, 'PerImagePredMR': 0.91, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.021, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.019, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.028, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.167, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.044, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.142}\n",
      "Validation Results: {'PerImagePredMP': 0.486, 'PerImagePredMR': 0.909, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.023, 'PerImageOneHopMP_at50_iou_0.5': 0.005, 'PerImageOneHopMR_at50_iou_0.5': 0.02, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.027, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.166, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.044, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.142}\n",
      "Step 26000: loss = 4.057000160217285 (78072.355 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.514, 'PerImagePredMR': 0.913, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.022, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.02, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.028, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.171, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.044, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.144}\n",
      "Validation Results: {'PerImagePredMP': 0.505, 'PerImagePredMR': 0.907, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.022, 'PerImageOneHopMP_at50_iou_0.5': 0.005, 'PerImageOneHopMR_at50_iou_0.5': 0.02, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.028, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.178, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.045, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.15}\n",
      "Step 27000: loss = 3.552000045776367 (81036.754 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.523, 'PerImagePredMR': 0.911, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.024, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.022, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.029, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.172, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.045, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.145}\n",
      "Validation Results: {'PerImagePredMP': 0.511, 'PerImagePredMR': 0.906, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.026, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.021, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.03, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.189, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.047, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.158}\n",
      "Step 28000: loss = 3.9100000858306885 (84059.199 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.527, 'PerImagePredMR': 0.913, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.024, 'PerImageOneHopMP_at50_iou_0.5': 0.007, 'PerImageOneHopMR_at50_iou_0.5': 0.021, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.029, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.178, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.046, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.15}\n",
      "Validation Results: {'PerImagePredMP': 0.529, 'PerImagePredMR': 0.9, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.027, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.021, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.028, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.177, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.044, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.147}\n",
      "Step 29000: loss = 4.363999843597412 (87062.208 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.517, 'PerImagePredMR': 0.907, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.023, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.02, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.027, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.166, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.043, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.143}\n",
      "Validation Results: {'PerImagePredMP': 0.52, 'PerImagePredMR': 0.907, 'PerImageOneHopMP_at100_iou_0.5': 0.003, 'PerImageOneHopMR_at100_iou_0.5': 0.022, 'PerImageOneHopMP_at50_iou_0.5': 0.005, 'PerImageOneHopMR_at50_iou_0.5': 0.019, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.029, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.177, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.047, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.151}\n",
      "Step 30000: loss = 3.9040000438690186 (90034.923 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.511, 'PerImagePredMR': 0.915, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.026, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.022, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.029, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.181, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.046, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.153}\n",
      "Validation Results: {'PerImagePredMP': 0.515, 'PerImagePredMR': 0.911, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.028, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.024, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.028, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.179, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.044, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.153}\n"
     ]
    }
   ],
   "source": [
    "trainer.train (\n",
    "    max_steps=30000,\n",
    "    train_eval_rate=100, \n",
    "    validation_rate=100, \n",
    "    verbose_rate=1000, \n",
    "    summary_rate=100, \n",
    "    checkpoint_rate=10000, \n",
    "    hyperparams = {\n",
    "        'learning_rate_generator': 1e-5 * batcher.batch_size,\n",
    "\n",
    "        'loss_factor_g_mil_ent': 1.0,\n",
    "        'loss_factor_g_mil_ent_conf': 0.0,\n",
    "        'loss_factor_g_mil_pred': 1.0,\n",
    "        'loss_factor_g_mil_pred_conf': 0.0,\n",
    "        'loss_factor_g_mil_role': 10.0,\n",
    "        'loss_factor_g_mil_box': 0.0,\n",
    "        'loss_factor_g_aux_emb_ent': 0.0,\n",
    "        'loss_factor_g_aux_emb_pred': 0.0,\n",
    "\n",
    "        'confidence_weight_on_role': 0.0,\n",
    "        'grad_clipping': 5.0,\n",
    "        'mil_iou_offset': 0.01,\n",
    "        'dropout_rate_g': 0.0,\n",
    "    },\n",
    "    validation_hyperparams = {\n",
    "        'dropout_rate_g': 0.0,\n",
    "        'confidence_weight_on_role': 0.0\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 31000: loss = 3.569999933242798 (2960.747 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.526, 'PerImagePredMR': 0.925, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.024, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.021, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.031, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.189, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.049, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.162}\n",
      "Validation Results: {'PerImagePredMP': 0.52, 'PerImagePredMR': 0.906, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.028, 'PerImageOneHopMP_at50_iou_0.5': 0.007, 'PerImageOneHopMR_at50_iou_0.5': 0.024, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.032, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.202, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.051, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.173}\n",
      "Step 32000: loss = 3.7899999618530273 (5904.352 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.522, 'PerImagePredMR': 0.926, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.028, 'PerImageOneHopMP_at50_iou_0.5': 0.008, 'PerImageOneHopMR_at50_iou_0.5': 0.024, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.033, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.204, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.052, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.17}\n",
      "Validation Results: {'PerImagePredMP': 0.519, 'PerImagePredMR': 0.911, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.027, 'PerImageOneHopMP_at50_iou_0.5': 0.007, 'PerImageOneHopMR_at50_iou_0.5': 0.024, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.034, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.206, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.054, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.173}\n",
      "Step 33000: loss = 3.5139999389648438 (8855.484 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.519, 'PerImagePredMR': 0.922, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.028, 'PerImageOneHopMP_at50_iou_0.5': 0.007, 'PerImageOneHopMR_at50_iou_0.5': 0.024, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.03, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.192, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.048, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.163}\n",
      "Validation Results: {'PerImagePredMP': 0.519, 'PerImagePredMR': 0.913, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.028, 'PerImageOneHopMP_at50_iou_0.5': 0.007, 'PerImageOneHopMR_at50_iou_0.5': 0.024, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.033, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.206, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.051, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.174}\n",
      "Step 34000: loss = 3.3389999866485596 (11793.511 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.526, 'PerImagePredMR': 0.929, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.027, 'PerImageOneHopMP_at50_iou_0.5': 0.008, 'PerImageOneHopMR_at50_iou_0.5': 0.023, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.033, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.199, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.053, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.168}\n",
      "Validation Results: {'PerImagePredMP': 0.519, 'PerImagePredMR': 0.912, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.031, 'PerImageOneHopMP_at50_iou_0.5': 0.007, 'PerImageOneHopMR_at50_iou_0.5': 0.025, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.034, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.21, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.053, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.179}\n",
      "Step 35000: loss = 3.6700000762939453 (14746.536 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.523, 'PerImagePredMR': 0.927, 'PerImageOneHopMP_at100_iou_0.5': 0.005, 'PerImageOneHopMR_at100_iou_0.5': 0.032, 'PerImageOneHopMP_at50_iou_0.5': 0.008, 'PerImageOneHopMR_at50_iou_0.5': 0.027, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.034, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.209, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.053, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.177}\n",
      "Validation Results: {'PerImagePredMP': 0.517, 'PerImagePredMR': 0.91, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.027, 'PerImageOneHopMP_at50_iou_0.5': 0.007, 'PerImageOneHopMR_at50_iou_0.5': 0.023, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.032, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.201, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.05, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.172}\n",
      "Step 36000: loss = 3.8510000705718994 (17671.657 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.516, 'PerImagePredMR': 0.924, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.027, 'PerImageOneHopMP_at50_iou_0.5': 0.007, 'PerImageOneHopMR_at50_iou_0.5': 0.024, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.034, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.209, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.053, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.177}\n",
      "Validation Results: {'PerImagePredMP': 0.516, 'PerImagePredMR': 0.914, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.029, 'PerImageOneHopMP_at50_iou_0.5': 0.006, 'PerImageOneHopMR_at50_iou_0.5': 0.027, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.032, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.198, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.049, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.172}\n",
      "Step 37000: loss = 4.163000106811523 (20634.008 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.522, 'PerImagePredMR': 0.929, 'PerImageOneHopMP_at100_iou_0.5': 0.005, 'PerImageOneHopMR_at100_iou_0.5': 0.033, 'PerImageOneHopMP_at50_iou_0.5': 0.008, 'PerImageOneHopMR_at50_iou_0.5': 0.029, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.034, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.211, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.054, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.174}\n",
      "Validation Results: {'PerImagePredMP': 0.52, 'PerImagePredMR': 0.912, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.028, 'PerImageOneHopMP_at50_iou_0.5': 0.007, 'PerImageOneHopMR_at50_iou_0.5': 0.025, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.034, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.208, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.054, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.178}\n",
      "Step 38000: loss = 4.441999912261963 (23571.815 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.519, 'PerImagePredMR': 0.929, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.028, 'PerImageOneHopMP_at50_iou_0.5': 0.007, 'PerImageOneHopMR_at50_iou_0.5': 0.024, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.033, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.206, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.052, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.174}\n",
      "Validation Results: {'PerImagePredMP': 0.519, 'PerImagePredMR': 0.912, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.033, 'PerImageOneHopMP_at50_iou_0.5': 0.007, 'PerImageOneHopMR_at50_iou_0.5': 0.027, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.034, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.207, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.054, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.175}\n",
      "Step 39000: loss = 3.1540000438690186 (26512.550 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.515, 'PerImagePredMR': 0.925, 'PerImageOneHopMP_at100_iou_0.5': 0.005, 'PerImageOneHopMR_at100_iou_0.5': 0.029, 'PerImageOneHopMP_at50_iou_0.5': 0.008, 'PerImageOneHopMR_at50_iou_0.5': 0.026, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.036, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.227, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.056, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.193}\n",
      "Validation Results: {'PerImagePredMP': 0.517, 'PerImagePredMR': 0.912, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.027, 'PerImageOneHopMP_at50_iou_0.5': 0.007, 'PerImageOneHopMR_at50_iou_0.5': 0.024, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.034, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.205, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.053, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.172}\n",
      "Step 40000: loss = 3.632999897003174 (29453.663 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.522, 'PerImagePredMR': 0.927, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.028, 'PerImageOneHopMP_at50_iou_0.5': 0.007, 'PerImageOneHopMR_at50_iou_0.5': 0.025, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.032, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.207, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.051, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.173}\n",
      "Validation Results: {'PerImagePredMP': 0.521, 'PerImagePredMR': 0.912, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.032, 'PerImageOneHopMP_at50_iou_0.5': 0.008, 'PerImageOneHopMR_at50_iou_0.5': 0.029, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.033, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.21, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.051, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.181}\n",
      "Step 41000: loss = 3.3350000381469727 (32379.428 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.519, 'PerImagePredMR': 0.925, 'PerImageOneHopMP_at100_iou_0.5': 0.005, 'PerImageOneHopMR_at100_iou_0.5': 0.033, 'PerImageOneHopMP_at50_iou_0.5': 0.009, 'PerImageOneHopMR_at50_iou_0.5': 0.029, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.035, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.208, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.055, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.175}\n",
      "Validation Results: {'PerImagePredMP': 0.514, 'PerImagePredMR': 0.913, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.029, 'PerImageOneHopMP_at50_iou_0.5': 0.007, 'PerImageOneHopMR_at50_iou_0.5': 0.027, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.034, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.202, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.053, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.172}\n",
      "Traceback (most recent call last):\n",
      "  File \"../../src/tensorflow/engine/trainer_3.py\", line 107, in train\n",
      "    results = self.sess.run(ops_to_run, feed_dict=feed_dict)\n",
      "  File \"/home/alireza/home_at_filer2/tools/anaconda3/envs/py3tf2/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/home/alireza/home_at_filer2/tools/anaconda3/envs/py3tf2/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/home/alireza/home_at_filer2/tools/anaconda3/envs/py3tf2/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/home/alireza/home_at_filer2/tools/anaconda3/envs/py3tf2/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/alireza/home_at_filer2/tools/anaconda3/envs/py3tf2/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"/home/alireza/home_at_filer2/tools/anaconda3/envs/py3tf2/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "KeyboardInterrupt\n",
      "\n",
      "Batch 1050/2275\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a3ad202af637>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     validation_hyperparams = {\n\u001b[1;32m     26\u001b[0m         \u001b[0;34m'dropout_rate_g'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;34m'confidence_weight_on_role'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     },\n\u001b[1;32m     29\u001b[0m )\n",
      "\u001b[0;32m/kiwi-data/users/alireza/vsp-net/src/tensorflow/engine/trainer_3.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, max_steps, train_eval_rate, validation_rate, verbose_rate, summary_rate, checkpoint_rate, hyperparams, validation_hyperparams, debug_mode, ignore_errors, save_last_checkpoint, stop_loss_ratio)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;31m# running one training step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops_to_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;31m# accumulating training evaluation results to pass to evaluate() function at once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/home_at_filer2/tools/anaconda3/envs/py3tf2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/home_at_filer2/tools/anaconda3/envs/py3tf2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/home_at_filer2/tools/anaconda3/envs/py3tf2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/home_at_filer2/tools/anaconda3/envs/py3tf2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/home_at_filer2/tools/anaconda3/envs/py3tf2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/home_at_filer2/tools/anaconda3/envs/py3tf2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train (\n",
    "    max_steps=20000,\n",
    "    train_eval_rate=100, \n",
    "    validation_rate=100, \n",
    "    verbose_rate=1000, \n",
    "    summary_rate=100, \n",
    "    checkpoint_rate=1000, \n",
    "    hyperparams = {\n",
    "        'learning_rate_generator': 1e-6 * batcher.batch_size,\n",
    "\n",
    "        'loss_factor_g_mil_ent': 1.0,\n",
    "        'loss_factor_g_mil_ent_conf': 0.0,\n",
    "        'loss_factor_g_mil_pred': 1.0,\n",
    "        'loss_factor_g_mil_pred_conf': 0.0,\n",
    "        'loss_factor_g_mil_role': 10.0,\n",
    "        'loss_factor_g_mil_box': 0.0,\n",
    "        'loss_factor_g_aux_emb_ent': 0.0,\n",
    "        'loss_factor_g_aux_emb_pred': 0.0,\n",
    "\n",
    "        'confidence_weight_on_role': 0.0,\n",
    "        'grad_clipping': 5.0,\n",
    "        'mil_iou_offset': 0.01,\n",
    "        'dropout_rate_g': 0.0,\n",
    "    },\n",
    "    validation_hyperparams = {\n",
    "        'dropout_rate_g': 0.0,\n",
    "        'confidence_weight_on_role': 0.0\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 41000: loss = 3.2279999256134033 (3015.233 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.517, 'PerImagePredMR': 0.927, 'PerImageOneHopMP_at100_iou_0.5': 0.005, 'PerImageOneHopMR_at100_iou_0.5': 0.033, 'PerImageOneHopMP_at50_iou_0.5': 0.008, 'PerImageOneHopMR_at50_iou_0.5': 0.03, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.034, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.214, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.053, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.179}\n",
      "Validation Results: {'PerImagePredMP': 0.516, 'PerImagePredMR': 0.913, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.03, 'PerImageOneHopMP_at50_iou_0.5': 0.008, 'PerImageOneHopMR_at50_iou_0.5': 0.028, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.034, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.218, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.053, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.183}\n",
      "Step 42000: loss = 3.3469998836517334 (5959.671 sec)\n",
      "Training Batch Evaluation Results: {'PerImagePredMP': 0.519, 'PerImagePredMR': 0.93, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.027, 'PerImageOneHopMP_at50_iou_0.5': 0.007, 'PerImageOneHopMR_at50_iou_0.5': 0.024, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.035, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.21, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.054, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.177}\n",
      "Validation Results: {'PerImagePredMP': 0.515, 'PerImagePredMR': 0.912, 'PerImageOneHopMP_at100_iou_0.5': 0.004, 'PerImageOneHopMR_at100_iou_0.5': 0.031, 'PerImageOneHopMP_at50_iou_0.5': 0.008, 'PerImageOneHopMR_at50_iou_0.5': 0.028, 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.034, 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.217, 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.054, 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.183}\n"
     ]
    }
   ],
   "source": [
    "trainer.train (\n",
    "    max_steps=5000,\n",
    "    train_eval_rate=100, \n",
    "    validation_rate=100, \n",
    "    verbose_rate=1000, \n",
    "    summary_rate=100, \n",
    "    checkpoint_rate=1000, \n",
    "    hyperparams = {\n",
    "        'learning_rate_generator': 1e-7 * batcher.batch_size,\n",
    "\n",
    "        'loss_factor_g_mil_ent': 1.0,\n",
    "        'loss_factor_g_mil_ent_conf': 0.0,\n",
    "        'loss_factor_g_mil_pred': 1.0,\n",
    "        'loss_factor_g_mil_pred_conf': 0.0,\n",
    "        'loss_factor_g_mil_role': 10.0,\n",
    "        'loss_factor_g_mil_box': 0.0,\n",
    "        'loss_factor_g_aux_emb_ent': 0.0,\n",
    "        'loss_factor_g_aux_emb_pred': 0.0,\n",
    "\n",
    "        'confidence_weight_on_role': 0.0,\n",
    "        'grad_clipping': 5.0,\n",
    "        'mil_iou_offset': 0.01,\n",
    "        'dropout_rate_g': 0.0,\n",
    "    },\n",
    "    validation_hyperparams = {\n",
    "        'dropout_rate_g': 0.0,\n",
    "        'confidence_weight_on_role': 0.0\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('final_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alireza/home_at_filer2/tools/anaconda3/envs/py3tf2/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../../checkpoint/exp_063/ckpt-45000\n"
     ]
    }
   ],
   "source": [
    "load_params(sess, os.path.join(codebase, 'checkpoint', exp_name, 'ckpt-45000'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evaluator = Evaluator({        \n",
    "    'graph_loader': gl,\n",
    "    'proposals': proposals,\n",
    "    'num_proposals': 20,\n",
    "    'filter_nonoverlap': True\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher_test = GraphBatcher(\n",
    "    gl, 32, proposals,\n",
    "    os.path.join(codebase, 'data', 'VG', 'xfeat_proposals', 'iresnet_oi_lowprop', 'feats_float32_20x1536.lmdb'), \n",
    "    dim_feats=1536,\n",
    "    seed=1237, \n",
    ")\n",
    "batcher_test.set_subset(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying\n",
      "Batch 1/808 done in 1 seconds. Spent time for read=0.01 (avg 0.01), processing=1.00 (avg 1.00), write=0.00 (avg 0.00) seconds.\n",
      "Batch 101/808 done in 5 seconds. Spent time for read=0.01 (avg 0.01), processing=0.04 (avg 0.05), write=0.00 (avg 0.00) seconds.\n",
      "Batch 201/808 done in 9 seconds. Spent time for read=0.00 (avg 0.01), processing=0.04 (avg 0.04), write=0.00 (avg 0.00) seconds.\n",
      "Batch 301/808 done in 14 seconds. Spent time for read=0.01 (avg 0.01), processing=0.04 (avg 0.04), write=0.00 (avg 0.00) seconds.\n",
      "Batch 401/808 done in 18 seconds. Spent time for read=0.01 (avg 0.01), processing=0.04 (avg 0.04), write=0.00 (avg 0.00) seconds.\n",
      "Batch 501/808 done in 23 seconds. Spent time for read=0.01 (avg 0.01), processing=0.04 (avg 0.04), write=0.00 (avg 0.00) seconds.\n",
      "Batch 601/808 done in 27 seconds. Spent time for read=0.01 (avg 0.01), processing=0.04 (avg 0.04), write=0.00 (avg 0.00) seconds.\n",
      "Batch 701/808 done in 32 seconds. Spent time for read=0.01 (avg 0.01), processing=0.04 (avg 0.04), write=0.00 (avg 0.00) seconds.\n",
      "Batch 801/808 done in 37 seconds. Spent time for read=0.01 (avg 0.01), processing=0.04 (avg 0.04), write=0.00 (avg 0.00) seconds.\n",
      "Batch 808/808 done in 37 seconds. Spent time for read=0.01 (avg 0.01), processing=0.04 (avg 0.04), write=0.00 (avg 0.00) seconds.\n",
      "Done in 37 seconds\n"
     ]
    }
   ],
   "source": [
    "#test_evaluator.reset()\n",
    "deploy(sess, model, batcher_test, test_evaluator, model.eval_ops,\n",
    "    hyperparams={\n",
    "        'dropout_rate_g': 0.0,\n",
    "        'confidence_weight_on_role': 0.0\n",
    "    },\n",
    "    ignore_errors=False,\n",
    "    debug_mode=False,\n",
    "    verbose_rate=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PerImagePredMP': 0.5169912976213498,\n",
       " 'PerImagePredMR': 0.9184643225170742,\n",
       " 'PerImageOneHopMP_at100_iou_0.5': 0.0043778766196093605,\n",
       " 'PerImageOneHopMR_at100_iou_0.5': 0.027631009981767672,\n",
       " 'PerImageOneHopMP_at50_iou_0.5': 0.0074260297814736035,\n",
       " 'PerImageOneHopMR_at50_iou_0.5': 0.0244146134574625,\n",
       " 'PerImageOneHopMP_phrase_at100_iou_0.5': 0.03303500290079289,\n",
       " 'PerImageOneHopMR_phrase_at100_iou_0.5': 0.19774083200113848,\n",
       " 'PerImageOneHopMP_phrase_at50_iou_0.5': 0.05198839682846646,\n",
       " 'PerImageOneHopMR_phrase_at50_iou_0.5': 0.16711022307855114}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = test_evaluator.evaluate()\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3 w/ Tensorflow 2",
   "language": "python",
   "name": "py3tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
