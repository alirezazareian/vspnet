{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data and Model Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'exp_064'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "codebase = '../../'\n",
    "sys.path.append(codebase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataflow.vg_graph_loader_3 import VGGraphLoader\n",
    "from src.dataflow.graph_batcher_4_rpn import GraphBatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.tensorflow.models.vsp_model_002 import Model\n",
    "from src.tensorflow.engine.trainer_3 import Trainer\n",
    "from src.tensorflow.engine.util import deploy, load_params\n",
    "from src.util.util import pickle_save, pickle_load\n",
    "from src.eval.sgg_evaluator_04 import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(1234)\n",
    "np.random.seed(1235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl = VGGraphLoader(\n",
    "    os.path.join(codebase, 'metadata', 'VG', 'prep', 'stanford', 'sg_stanford_2.pkl'),\n",
    "    os.path.join(codebase, 'metadata', 'VG', 'prep', 'stanford', 'word_emb_stanford_2.pkl'),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids, train_idx, test_idx = pickle_load(os.path.join(codebase, 'metadata', 'VG', 'prep', 'stanford', 'split_stanford.pkl'))\n",
    "misc = pickle_load(os.path.join(codebase, 'metadata', 'VG', 'prep', 'stanford', 'misc_stanford_2.pkl'))\n",
    "img_no_ent = misc['img_no_ent']\n",
    "img_no_pred = misc['img_no_pred']\n",
    "image_size = misc['img_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.asarray(list(set(train_idx) - set(img_no_ent)))\n",
    "np.random.shuffle(train_idx)\n",
    "val_idx = train_idx[:1000]\n",
    "train_idx = train_idx[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals = pickle_load(os.path.join(codebase, 'data', 'VG', 'xfeat_gtbox', 'iresnet_oi_lowprop', 'coords.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = GraphBatcher(\n",
    "    gl, 32, proposals,\n",
    "    os.path.join(codebase, 'data', 'VG', 'xfeat_gtbox', 'iresnet_oi_lowprop', 'feats_float32_20x1536.lmdb'), \n",
    "    dim_feats=1536,\n",
    "    seed=1236, \n",
    ")\n",
    "batcher.set_subset(train_idx)\n",
    "batcher.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher_val = GraphBatcher(\n",
    "    gl, 32, proposals,\n",
    "    os.path.join(codebase, 'data', 'VG', 'xfeat_gtbox', 'iresnet_oi_lowprop', 'feats_float32_20x1536.lmdb'), \n",
    "    dim_feats=1536,\n",
    "    seed=1237, \n",
    ")\n",
    "batcher_val.set_subset(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../../src/tensorflow/models/vsp_model_002.py:94: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/alireza/home_at_filer2/tools/anaconda3/envs/py3tf2/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From ../../src/tensorflow/util/util.py:15: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From ../../src/tensorflow/util/util.py:17: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From ../../src/tensorflow/models/vsp_model_002.py:513: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "WARNING:tensorflow:From /home/alireza/home_at_filer2/tools/anaconda3/envs/py3tf2/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model = Model(   \n",
    "    dim_att_head_role_ent=[1024, 1024], \n",
    "    dim_att_head_role_pred=[1024, 1024],\n",
    "    role_edge_mode='full_soft',\n",
    "    stop_grad_role_edge=True,\n",
    "    \n",
    "    dim_state_ent=1024,\n",
    "    dim_state_pred=1024,\n",
    "    dim_emb_head_ent=[300],\n",
    "    dim_conf_head_ent=[],\n",
    "    dim_conf_head_pred=[],\n",
    "    dim_emb_head_pred=[300],\n",
    "    dim_init_head_ent=[1024],\n",
    "\n",
    "    dim_message_send_head_pred2ent=[1024, 1024],\n",
    "    dim_message_pool_head_pred2ent=[1024, 1024],\n",
    "    dim_message_receive_head_pred2ent=[1024, 1024],    \n",
    "    dim_message_send_head_ent2pred=[1024, 1024],\n",
    "    dim_message_pool_head_ent2pred=[1024, 1024],\n",
    "    dim_message_receive_head_ent2pred=[1024, 1024],\n",
    "    \n",
    "    num_mp_iter=3,     \n",
    "    num_proposals=None,\n",
    "\n",
    "    heat_role=1.0,\n",
    "    heat_emb_mil=1.0,\n",
    "    null_att_logit=0.0,\n",
    "        \n",
    "    num_align_iter=3,\n",
    "    alignment_order='best',\n",
    "    default_act_fn_name='leaky_relu',\n",
    "    optimizer_type_generator=tf.train.AdamOptimizer,\n",
    "    \n",
    "    max_num_pred=100,\n",
    "    dim_init_head_pred=[],\n",
    "    init_state_type_pred='trainable',\n",
    "    \n",
    "    dim_proposal_feat=1536,\n",
    "    emb_dict_ent=gl.noun_emb_dict,\n",
    "    emb_dict_pred=gl.pred_emb_dict,    \n",
    "    #image_size=448,\n",
    "    #num_channels=3,\n",
    "    debugging=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "#sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True)))\n",
    "#sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.5)))\n",
    "sess = tf.Session()\n",
    "sess.run(tf.no_op())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evaluator = Evaluator({        \n",
    "    'graph_loader': gl,\n",
    "    'proposals': proposals,\n",
    "    'num_proposals': None,\n",
    "    'filter_nonoverlap': True,\n",
    "    'rank_triplet_confidence': False,\n",
    "})\n",
    "val_evaluator = Evaluator({        \n",
    "    'graph_loader': gl,\n",
    "    'proposals': proposals,\n",
    "    'num_proposals': None,\n",
    "    'filter_nonoverlap': True,\n",
    "    'rank_triplet_confidence': False,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model, sess, batcher, batcher_val, train_evaluator, val_evaluator,\n",
    "    logdir=os.path.join(codebase, 'log', 'tfsummary', exp_name), \n",
    "    modeldir=os.path.join(codebase, 'checkpoint', exp_name),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../src/eval/eval_utils.py:55: RuntimeWarning: invalid value encountered in true_divide\n",
      "  iou = intsec / (area1[:, np.newaxis] + area2[np.newaxis, :] - intsec)\n",
      "../../src/eval/graph_util_new_02.py:118: RuntimeWarning: invalid value encountered in greater\n",
      "  overlap = (pw_iou(ent_box[i], ent_box[i]) > 0.0).astype(np.float32)\n",
      "../../src/eval/graph_eval_3.py:219: RuntimeWarning: invalid value encountered in true_divide\n",
      "  per_image_recall.append(np.divide(len(gt_matched), len(gt_graph['pred_lbl'][i])))\n",
      "../../src/eval/graph_eval_3.py:300: RuntimeWarning: invalid value encountered in true_divide\n",
      "  per_image_recall.append(np.divide(len(gt_matched), len(gt_graph['pred_lbl'][i])))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000: loss = 3.046999931335449 (1510.052 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.015, 'PerImageOneHopMR_at100_iou_0.5': 0.22, 'PerImageOneHopMP_at50_iou_0.5': 0.026, 'PerImageOneHopMR_at50_iou_0.5': 0.2, 'PerImageLocPredMP_at100_iou_0.5': 0.032, 'PerImageLocPredMR_at100_iou_0.5': 0.478, 'PerImageLocPredMP_at50_iou_0.5': 0.054, 'PerImageLocPredMR_at50_iou_0.5': 0.428}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.014, 'PerImageOneHopMR_at100_iou_0.5': 0.216, 'PerImageOneHopMP_at50_iou_0.5': 0.025, 'PerImageOneHopMR_at50_iou_0.5': 0.206, 'PerImageLocPredMP_at100_iou_0.5': 0.03, 'PerImageLocPredMR_at100_iou_0.5': 0.481, 'PerImageLocPredMP_at50_iou_0.5': 0.054, 'PerImageLocPredMR_at50_iou_0.5': 0.445}\n",
      "Step 2000: loss = 2.4860000610351562 (2769.792 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.017, 'PerImageOneHopMR_at100_iou_0.5': 0.247, 'PerImageOneHopMP_at50_iou_0.5': 0.029, 'PerImageOneHopMR_at50_iou_0.5': 0.223, 'PerImageLocPredMP_at100_iou_0.5': 0.035, 'PerImageLocPredMR_at100_iou_0.5': 0.526, 'PerImageLocPredMP_at50_iou_0.5': 0.061, 'PerImageLocPredMR_at50_iou_0.5': 0.473}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.016, 'PerImageOneHopMR_at100_iou_0.5': 0.241, 'PerImageOneHopMP_at50_iou_0.5': 0.029, 'PerImageOneHopMR_at50_iou_0.5': 0.221, 'PerImageLocPredMP_at100_iou_0.5': 0.035, 'PerImageLocPredMR_at100_iou_0.5': 0.526, 'PerImageLocPredMP_at50_iou_0.5': 0.06, 'PerImageLocPredMR_at50_iou_0.5': 0.474}\n",
      "Step 3000: loss = 2.802000045776367 (3944.188 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.018, 'PerImageOneHopMR_at100_iou_0.5': 0.25, 'PerImageOneHopMP_at50_iou_0.5': 0.032, 'PerImageOneHopMR_at50_iou_0.5': 0.226, 'PerImageLocPredMP_at100_iou_0.5': 0.037, 'PerImageLocPredMR_at100_iou_0.5': 0.526, 'PerImageLocPredMP_at50_iou_0.5': 0.064, 'PerImageLocPredMR_at50_iou_0.5': 0.476}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.015, 'PerImageOneHopMR_at100_iou_0.5': 0.229, 'PerImageOneHopMP_at50_iou_0.5': 0.027, 'PerImageOneHopMR_at50_iou_0.5': 0.215, 'PerImageLocPredMP_at100_iou_0.5': 0.034, 'PerImageLocPredMR_at100_iou_0.5': 0.539, 'PerImageLocPredMP_at50_iou_0.5': 0.061, 'PerImageLocPredMR_at50_iou_0.5': 0.501}\n",
      "Step 4000: loss = 2.3350000381469727 (5109.665 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.018, 'PerImageOneHopMR_at100_iou_0.5': 0.26, 'PerImageOneHopMP_at50_iou_0.5': 0.032, 'PerImageOneHopMR_at50_iou_0.5': 0.24, 'PerImageLocPredMP_at100_iou_0.5': 0.037, 'PerImageLocPredMR_at100_iou_0.5': 0.549, 'PerImageLocPredMP_at50_iou_0.5': 0.065, 'PerImageLocPredMR_at50_iou_0.5': 0.499}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.017, 'PerImageOneHopMR_at100_iou_0.5': 0.258, 'PerImageOneHopMP_at50_iou_0.5': 0.032, 'PerImageOneHopMR_at50_iou_0.5': 0.241, 'PerImageLocPredMP_at100_iou_0.5': 0.037, 'PerImageLocPredMR_at100_iou_0.5': 0.559, 'PerImageLocPredMP_at50_iou_0.5': 0.067, 'PerImageLocPredMR_at50_iou_0.5': 0.517}\n",
      "Step 5000: loss = 2.4570000171661377 (6278.847 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.02, 'PerImageOneHopMR_at100_iou_0.5': 0.277, 'PerImageOneHopMP_at50_iou_0.5': 0.036, 'PerImageOneHopMR_at50_iou_0.5': 0.252, 'PerImageLocPredMP_at100_iou_0.5': 0.04, 'PerImageLocPredMR_at100_iou_0.5': 0.566, 'PerImageLocPredMP_at50_iou_0.5': 0.071, 'PerImageLocPredMR_at50_iou_0.5': 0.51}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.018, 'PerImageOneHopMR_at100_iou_0.5': 0.266, 'PerImageOneHopMP_at50_iou_0.5': 0.032, 'PerImageOneHopMR_at50_iou_0.5': 0.24, 'PerImageLocPredMP_at100_iou_0.5': 0.038, 'PerImageLocPredMR_at100_iou_0.5': 0.561, 'PerImageLocPredMP_at50_iou_0.5': 0.064, 'PerImageLocPredMR_at50_iou_0.5': 0.494}\n",
      "Step 7000: loss = 2.5320000648498535 (8642.177 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.022, 'PerImageOneHopMR_at100_iou_0.5': 0.3, 'PerImageOneHopMP_at50_iou_0.5': 0.039, 'PerImageOneHopMR_at50_iou_0.5': 0.272, 'PerImageLocPredMP_at100_iou_0.5': 0.042, 'PerImageLocPredMR_at100_iou_0.5': 0.595, 'PerImageLocPredMP_at50_iou_0.5': 0.074, 'PerImageLocPredMR_at50_iou_0.5': 0.533}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.02, 'PerImageOneHopMR_at100_iou_0.5': 0.273, 'PerImageOneHopMP_at50_iou_0.5': 0.036, 'PerImageOneHopMR_at50_iou_0.5': 0.253, 'PerImageLocPredMP_at100_iou_0.5': 0.04, 'PerImageLocPredMR_at100_iou_0.5': 0.566, 'PerImageLocPredMP_at50_iou_0.5': 0.072, 'PerImageLocPredMR_at50_iou_0.5': 0.515}\n",
      "Step 8000: loss = 2.6989998817443848 (9813.492 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.021, 'PerImageOneHopMR_at100_iou_0.5': 0.303, 'PerImageOneHopMP_at50_iou_0.5': 0.038, 'PerImageOneHopMR_at50_iou_0.5': 0.274, 'PerImageLocPredMP_at100_iou_0.5': 0.041, 'PerImageLocPredMR_at100_iou_0.5': 0.593, 'PerImageLocPredMP_at50_iou_0.5': 0.071, 'PerImageLocPredMR_at50_iou_0.5': 0.535}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.02, 'PerImageOneHopMR_at100_iou_0.5': 0.288, 'PerImageOneHopMP_at50_iou_0.5': 0.036, 'PerImageOneHopMR_at50_iou_0.5': 0.267, 'PerImageLocPredMP_at100_iou_0.5': 0.041, 'PerImageLocPredMR_at100_iou_0.5': 0.588, 'PerImageLocPredMP_at50_iou_0.5': 0.074, 'PerImageLocPredMR_at50_iou_0.5': 0.537}\n",
      "Step 9000: loss = 2.115999937057495 (10986.010 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.021, 'PerImageOneHopMR_at100_iou_0.5': 0.302, 'PerImageOneHopMP_at50_iou_0.5': 0.037, 'PerImageOneHopMR_at50_iou_0.5': 0.273, 'PerImageLocPredMP_at100_iou_0.5': 0.041, 'PerImageLocPredMR_at100_iou_0.5': 0.596, 'PerImageLocPredMP_at50_iou_0.5': 0.072, 'PerImageLocPredMR_at50_iou_0.5': 0.533}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.02, 'PerImageOneHopMR_at100_iou_0.5': 0.283, 'PerImageOneHopMP_at50_iou_0.5': 0.036, 'PerImageOneHopMR_at50_iou_0.5': 0.256, 'PerImageLocPredMP_at100_iou_0.5': 0.04, 'PerImageLocPredMR_at100_iou_0.5': 0.587, 'PerImageLocPredMP_at50_iou_0.5': 0.071, 'PerImageLocPredMR_at50_iou_0.5': 0.531}\n",
      "Step 10000: loss = 2.0899999141693115 (12159.250 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.023, 'PerImageOneHopMR_at100_iou_0.5': 0.322, 'PerImageOneHopMP_at50_iou_0.5': 0.04, 'PerImageOneHopMR_at50_iou_0.5': 0.288, 'PerImageLocPredMP_at100_iou_0.5': 0.042, 'PerImageLocPredMR_at100_iou_0.5': 0.618, 'PerImageLocPredMP_at50_iou_0.5': 0.074, 'PerImageLocPredMR_at50_iou_0.5': 0.55}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.021, 'PerImageOneHopMR_at100_iou_0.5': 0.288, 'PerImageOneHopMP_at50_iou_0.5': 0.037, 'PerImageOneHopMR_at50_iou_0.5': 0.261, 'PerImageLocPredMP_at100_iou_0.5': 0.041, 'PerImageLocPredMR_at100_iou_0.5': 0.588, 'PerImageLocPredMP_at50_iou_0.5': 0.071, 'PerImageLocPredMR_at50_iou_0.5': 0.524}\n",
      "Step 11000: loss = 2.0409998893737793 (13337.911 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.025, 'PerImageOneHopMR_at100_iou_0.5': 0.323, 'PerImageOneHopMP_at50_iou_0.5': 0.044, 'PerImageOneHopMR_at50_iou_0.5': 0.292, 'PerImageLocPredMP_at100_iou_0.5': 0.047, 'PerImageLocPredMR_at100_iou_0.5': 0.625, 'PerImageLocPredMP_at50_iou_0.5': 0.082, 'PerImageLocPredMR_at50_iou_0.5': 0.561}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.021, 'PerImageOneHopMR_at100_iou_0.5': 0.298, 'PerImageOneHopMP_at50_iou_0.5': 0.038, 'PerImageOneHopMR_at50_iou_0.5': 0.277, 'PerImageLocPredMP_at100_iou_0.5': 0.041, 'PerImageLocPredMR_at100_iou_0.5': 0.585, 'PerImageLocPredMP_at50_iou_0.5': 0.073, 'PerImageLocPredMR_at50_iou_0.5': 0.538}\n",
      "Step 12000: loss = 2.0169999599456787 (14511.775 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.024, 'PerImageOneHopMR_at100_iou_0.5': 0.318, 'PerImageOneHopMP_at50_iou_0.5': 0.04, 'PerImageOneHopMR_at50_iou_0.5': 0.285, 'PerImageLocPredMP_at100_iou_0.5': 0.045, 'PerImageLocPredMR_at100_iou_0.5': 0.62, 'PerImageLocPredMP_at50_iou_0.5': 0.076, 'PerImageLocPredMR_at50_iou_0.5': 0.551}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.022, 'PerImageOneHopMR_at100_iou_0.5': 0.292, 'PerImageOneHopMP_at50_iou_0.5': 0.039, 'PerImageOneHopMR_at50_iou_0.5': 0.27, 'PerImageLocPredMP_at100_iou_0.5': 0.043, 'PerImageLocPredMR_at100_iou_0.5': 0.593, 'PerImageLocPredMP_at50_iou_0.5': 0.075, 'PerImageLocPredMR_at50_iou_0.5': 0.545}\n",
      "Step 13000: loss = 1.7109999656677246 (15683.707 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.023, 'PerImageOneHopMR_at100_iou_0.5': 0.327, 'PerImageOneHopMP_at50_iou_0.5': 0.041, 'PerImageOneHopMR_at50_iou_0.5': 0.298, 'PerImageLocPredMP_at100_iou_0.5': 0.044, 'PerImageLocPredMR_at100_iou_0.5': 0.631, 'PerImageLocPredMP_at50_iou_0.5': 0.076, 'PerImageLocPredMR_at50_iou_0.5': 0.569}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.021, 'PerImageOneHopMR_at100_iou_0.5': 0.295, 'PerImageOneHopMP_at50_iou_0.5': 0.037, 'PerImageOneHopMR_at50_iou_0.5': 0.272, 'PerImageLocPredMP_at100_iou_0.5': 0.042, 'PerImageLocPredMR_at100_iou_0.5': 0.591, 'PerImageLocPredMP_at50_iou_0.5': 0.074, 'PerImageLocPredMR_at50_iou_0.5': 0.536}\n",
      "Step 14000: loss = 1.7690000534057617 (16867.952 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.026, 'PerImageOneHopMR_at100_iou_0.5': 0.344, 'PerImageOneHopMP_at50_iou_0.5': 0.045, 'PerImageOneHopMR_at50_iou_0.5': 0.313, 'PerImageLocPredMP_at100_iou_0.5': 0.047, 'PerImageLocPredMR_at100_iou_0.5': 0.641, 'PerImageLocPredMP_at50_iou_0.5': 0.08, 'PerImageLocPredMR_at50_iou_0.5': 0.575}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.022, 'PerImageOneHopMR_at100_iou_0.5': 0.299, 'PerImageOneHopMP_at50_iou_0.5': 0.04, 'PerImageOneHopMR_at50_iou_0.5': 0.274, 'PerImageLocPredMP_at100_iou_0.5': 0.043, 'PerImageLocPredMR_at100_iou_0.5': 0.591, 'PerImageLocPredMP_at50_iou_0.5': 0.076, 'PerImageLocPredMR_at50_iou_0.5': 0.54}\n",
      "Step 16000: loss = 2.117000102996826 (19219.639 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.025, 'PerImageOneHopMR_at100_iou_0.5': 0.339, 'PerImageOneHopMP_at50_iou_0.5': 0.045, 'PerImageOneHopMR_at50_iou_0.5': 0.308, 'PerImageLocPredMP_at100_iou_0.5': 0.047, 'PerImageLocPredMR_at100_iou_0.5': 0.646, 'PerImageLocPredMP_at50_iou_0.5': 0.08, 'PerImageLocPredMR_at50_iou_0.5': 0.576}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.022, 'PerImageOneHopMR_at100_iou_0.5': 0.287, 'PerImageOneHopMP_at50_iou_0.5': 0.038, 'PerImageOneHopMR_at50_iou_0.5': 0.265, 'PerImageLocPredMP_at100_iou_0.5': 0.043, 'PerImageLocPredMR_at100_iou_0.5': 0.589, 'PerImageLocPredMP_at50_iou_0.5': 0.074, 'PerImageLocPredMR_at50_iou_0.5': 0.537}\n",
      "Step 17000: loss = 2.0910000801086426 (20391.871 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.026, 'PerImageOneHopMR_at100_iou_0.5': 0.349, 'PerImageOneHopMP_at50_iou_0.5': 0.046, 'PerImageOneHopMR_at50_iou_0.5': 0.313, 'PerImageLocPredMP_at100_iou_0.5': 0.048, 'PerImageLocPredMR_at100_iou_0.5': 0.656, 'PerImageLocPredMP_at50_iou_0.5': 0.082, 'PerImageLocPredMR_at50_iou_0.5': 0.587}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.022, 'PerImageOneHopMR_at100_iou_0.5': 0.29, 'PerImageOneHopMP_at50_iou_0.5': 0.039, 'PerImageOneHopMR_at50_iou_0.5': 0.267, 'PerImageLocPredMP_at100_iou_0.5': 0.044, 'PerImageLocPredMR_at100_iou_0.5': 0.596, 'PerImageLocPredMP_at50_iou_0.5': 0.077, 'PerImageLocPredMR_at50_iou_0.5': 0.539}\n",
      "Step 18000: loss = 1.597000002861023 (21571.863 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.026, 'PerImageOneHopMR_at100_iou_0.5': 0.363, 'PerImageOneHopMP_at50_iou_0.5': 0.045, 'PerImageOneHopMR_at50_iou_0.5': 0.325, 'PerImageLocPredMP_at100_iou_0.5': 0.048, 'PerImageLocPredMR_at100_iou_0.5': 0.666, 'PerImageLocPredMP_at50_iou_0.5': 0.082, 'PerImageLocPredMR_at50_iou_0.5': 0.593}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.023, 'PerImageOneHopMR_at100_iou_0.5': 0.295, 'PerImageOneHopMP_at50_iou_0.5': 0.04, 'PerImageOneHopMR_at50_iou_0.5': 0.271, 'PerImageLocPredMP_at100_iou_0.5': 0.045, 'PerImageLocPredMR_at100_iou_0.5': 0.591, 'PerImageLocPredMP_at50_iou_0.5': 0.077, 'PerImageLocPredMR_at50_iou_0.5': 0.537}\n",
      "Step 19000: loss = 1.2799999713897705 (22751.331 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.027, 'PerImageOneHopMR_at100_iou_0.5': 0.369, 'PerImageOneHopMP_at50_iou_0.5': 0.046, 'PerImageOneHopMR_at50_iou_0.5': 0.332, 'PerImageLocPredMP_at100_iou_0.5': 0.048, 'PerImageLocPredMR_at100_iou_0.5': 0.675, 'PerImageLocPredMP_at50_iou_0.5': 0.081, 'PerImageLocPredMR_at50_iou_0.5': 0.599}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.022, 'PerImageOneHopMR_at100_iou_0.5': 0.29, 'PerImageOneHopMP_at50_iou_0.5': 0.038, 'PerImageOneHopMR_at50_iou_0.5': 0.268, 'PerImageLocPredMP_at100_iou_0.5': 0.045, 'PerImageLocPredMR_at100_iou_0.5': 0.613, 'PerImageLocPredMP_at50_iou_0.5': 0.077, 'PerImageLocPredMR_at50_iou_0.5': 0.558}\n",
      "Step 20000: loss = 1.7259999513626099 (23929.707 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.027, 'PerImageOneHopMR_at100_iou_0.5': 0.367, 'PerImageOneHopMP_at50_iou_0.5': 0.047, 'PerImageOneHopMR_at50_iou_0.5': 0.333, 'PerImageLocPredMP_at100_iou_0.5': 0.05, 'PerImageLocPredMR_at100_iou_0.5': 0.672, 'PerImageLocPredMP_at50_iou_0.5': 0.085, 'PerImageLocPredMR_at50_iou_0.5': 0.604}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.021, 'PerImageOneHopMR_at100_iou_0.5': 0.289, 'PerImageOneHopMP_at50_iou_0.5': 0.037, 'PerImageOneHopMR_at50_iou_0.5': 0.267, 'PerImageLocPredMP_at100_iou_0.5': 0.042, 'PerImageLocPredMR_at100_iou_0.5': 0.591, 'PerImageLocPredMP_at50_iou_0.5': 0.072, 'PerImageLocPredMR_at50_iou_0.5': 0.541}\n"
     ]
    }
   ],
   "source": [
    "trainer.train (\n",
    "    max_steps=20000,\n",
    "    train_eval_rate=100, \n",
    "    validation_rate=100, \n",
    "    verbose_rate=1000, \n",
    "    summary_rate=100, \n",
    "    checkpoint_rate=10000, \n",
    "    hyperparams = {\n",
    "        'learning_rate_generator': 1e-5 * batcher.batch_size,\n",
    "\n",
    "        'loss_factor_g_mil_ent': 1.0,\n",
    "        'loss_factor_g_mil_ent_conf': 0.0,\n",
    "        'loss_factor_g_mil_pred': 1.0,\n",
    "        'loss_factor_g_mil_pred_conf': 0.0,\n",
    "        'loss_factor_g_mil_role': 10.0,\n",
    "        'loss_factor_g_mil_box': 10.0,\n",
    "        'loss_factor_g_aux_emb_ent': 0.0,\n",
    "        'loss_factor_g_aux_emb_pred': 0.0,\n",
    "\n",
    "        'confidence_weight_on_role': 0.0,\n",
    "        'grad_clipping': 5.0,\n",
    "        'mil_iou_offset': 0.01,\n",
    "        'dropout_rate_g': 0.0,\n",
    "    },\n",
    "    validation_hyperparams = {\n",
    "        'dropout_rate_g': 0.0,\n",
    "        'confidence_weight_on_role': 0.0\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21000: loss = 1.6770000457763672 (1179.816 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.029, 'PerImageOneHopMR_at100_iou_0.5': 0.404, 'PerImageOneHopMP_at50_iou_0.5': 0.05, 'PerImageOneHopMR_at50_iou_0.5': 0.363, 'PerImageLocPredMP_at100_iou_0.5': 0.05, 'PerImageLocPredMR_at100_iou_0.5': 0.7, 'PerImageLocPredMP_at50_iou_0.5': 0.085, 'PerImageLocPredMR_at50_iou_0.5': 0.626}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.024, 'PerImageOneHopMR_at100_iou_0.5': 0.32, 'PerImageOneHopMP_at50_iou_0.5': 0.043, 'PerImageOneHopMR_at50_iou_0.5': 0.294, 'PerImageLocPredMP_at100_iou_0.5': 0.047, 'PerImageLocPredMR_at100_iou_0.5': 0.631, 'PerImageLocPredMP_at50_iou_0.5': 0.081, 'PerImageLocPredMR_at50_iou_0.5': 0.576}\n",
      "Step 22000: loss = 1.281999945640564 (2358.684 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.032, 'PerImageOneHopMR_at100_iou_0.5': 0.434, 'PerImageOneHopMP_at50_iou_0.5': 0.056, 'PerImageOneHopMR_at50_iou_0.5': 0.386, 'PerImageLocPredMP_at100_iou_0.5': 0.054, 'PerImageLocPredMR_at100_iou_0.5': 0.732, 'PerImageLocPredMP_at50_iou_0.5': 0.092, 'PerImageLocPredMR_at50_iou_0.5': 0.644}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.024, 'PerImageOneHopMR_at100_iou_0.5': 0.323, 'PerImageOneHopMP_at50_iou_0.5': 0.043, 'PerImageOneHopMR_at50_iou_0.5': 0.297, 'PerImageLocPredMP_at100_iou_0.5': 0.047, 'PerImageLocPredMR_at100_iou_0.5': 0.63, 'PerImageLocPredMP_at50_iou_0.5': 0.082, 'PerImageLocPredMR_at50_iou_0.5': 0.574}\n",
      "Step 23000: loss = 1.7799999713897705 (3540.546 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.032, 'PerImageOneHopMR_at100_iou_0.5': 0.426, 'PerImageOneHopMP_at50_iou_0.5': 0.055, 'PerImageOneHopMR_at50_iou_0.5': 0.383, 'PerImageLocPredMP_at100_iou_0.5': 0.053, 'PerImageLocPredMR_at100_iou_0.5': 0.73, 'PerImageLocPredMP_at50_iou_0.5': 0.091, 'PerImageLocPredMR_at50_iou_0.5': 0.648}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.025, 'PerImageOneHopMR_at100_iou_0.5': 0.331, 'PerImageOneHopMP_at50_iou_0.5': 0.044, 'PerImageOneHopMR_at50_iou_0.5': 0.303, 'PerImageLocPredMP_at100_iou_0.5': 0.047, 'PerImageLocPredMR_at100_iou_0.5': 0.624, 'PerImageLocPredMP_at50_iou_0.5': 0.082, 'PerImageLocPredMR_at50_iou_0.5': 0.57}\n",
      "Step 24000: loss = 1.4019999504089355 (4721.672 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.032, 'PerImageOneHopMR_at100_iou_0.5': 0.445, 'PerImageOneHopMP_at50_iou_0.5': 0.055, 'PerImageOneHopMR_at50_iou_0.5': 0.398, 'PerImageLocPredMP_at100_iou_0.5': 0.054, 'PerImageLocPredMR_at100_iou_0.5': 0.745, 'PerImageLocPredMP_at50_iou_0.5': 0.092, 'PerImageLocPredMR_at50_iou_0.5': 0.66}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.025, 'PerImageOneHopMR_at100_iou_0.5': 0.332, 'PerImageOneHopMP_at50_iou_0.5': 0.045, 'PerImageOneHopMR_at50_iou_0.5': 0.302, 'PerImageLocPredMP_at100_iou_0.5': 0.048, 'PerImageLocPredMR_at100_iou_0.5': 0.635, 'PerImageLocPredMP_at50_iou_0.5': 0.084, 'PerImageLocPredMR_at50_iou_0.5': 0.576}\n",
      "Step 25000: loss = 1.437999963760376 (5892.180 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.031, 'PerImageOneHopMR_at100_iou_0.5': 0.437, 'PerImageOneHopMP_at50_iou_0.5': 0.054, 'PerImageOneHopMR_at50_iou_0.5': 0.392, 'PerImageLocPredMP_at100_iou_0.5': 0.053, 'PerImageLocPredMR_at100_iou_0.5': 0.74, 'PerImageLocPredMP_at50_iou_0.5': 0.088, 'PerImageLocPredMR_at50_iou_0.5': 0.65}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.026, 'PerImageOneHopMR_at100_iou_0.5': 0.334, 'PerImageOneHopMP_at50_iou_0.5': 0.045, 'PerImageOneHopMR_at50_iou_0.5': 0.304, 'PerImageLocPredMP_at100_iou_0.5': 0.048, 'PerImageLocPredMR_at100_iou_0.5': 0.631, 'PerImageLocPredMP_at50_iou_0.5': 0.083, 'PerImageLocPredMR_at50_iou_0.5': 0.571}\n",
      "Step 26000: loss = 1.4149999618530273 (7058.610 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.033, 'PerImageOneHopMR_at100_iou_0.5': 0.452, 'PerImageOneHopMP_at50_iou_0.5': 0.057, 'PerImageOneHopMR_at50_iou_0.5': 0.406, 'PerImageLocPredMP_at100_iou_0.5': 0.054, 'PerImageLocPredMR_at100_iou_0.5': 0.754, 'PerImageLocPredMP_at50_iou_0.5': 0.091, 'PerImageLocPredMR_at50_iou_0.5': 0.673}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.025, 'PerImageOneHopMR_at100_iou_0.5': 0.329, 'PerImageOneHopMP_at50_iou_0.5': 0.043, 'PerImageOneHopMR_at50_iou_0.5': 0.298, 'PerImageLocPredMP_at100_iou_0.5': 0.047, 'PerImageLocPredMR_at100_iou_0.5': 0.632, 'PerImageLocPredMP_at50_iou_0.5': 0.082, 'PerImageLocPredMR_at50_iou_0.5': 0.573}\n",
      "Step 27000: loss = 1.4509999752044678 (8241.585 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.033, 'PerImageOneHopMR_at100_iou_0.5': 0.445, 'PerImageOneHopMP_at50_iou_0.5': 0.055, 'PerImageOneHopMR_at50_iou_0.5': 0.392, 'PerImageLocPredMP_at100_iou_0.5': 0.055, 'PerImageLocPredMR_at100_iou_0.5': 0.754, 'PerImageLocPredMP_at50_iou_0.5': 0.091, 'PerImageLocPredMR_at50_iou_0.5': 0.658}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.025, 'PerImageOneHopMR_at100_iou_0.5': 0.335, 'PerImageOneHopMP_at50_iou_0.5': 0.044, 'PerImageOneHopMR_at50_iou_0.5': 0.306, 'PerImageLocPredMP_at100_iou_0.5': 0.048, 'PerImageLocPredMR_at100_iou_0.5': 0.642, 'PerImageLocPredMP_at50_iou_0.5': 0.083, 'PerImageLocPredMR_at50_iou_0.5': 0.582}\n",
      "Step 28000: loss = 1.4490000009536743 (9418.212 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.035, 'PerImageOneHopMR_at100_iou_0.5': 0.473, 'PerImageOneHopMP_at50_iou_0.5': 0.06, 'PerImageOneHopMR_at50_iou_0.5': 0.419, 'PerImageLocPredMP_at100_iou_0.5': 0.058, 'PerImageLocPredMR_at100_iou_0.5': 0.777, 'PerImageLocPredMP_at50_iou_0.5': 0.097, 'PerImageLocPredMR_at50_iou_0.5': 0.689}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.025, 'PerImageOneHopMR_at100_iou_0.5': 0.326, 'PerImageOneHopMP_at50_iou_0.5': 0.044, 'PerImageOneHopMR_at50_iou_0.5': 0.3, 'PerImageLocPredMP_at100_iou_0.5': 0.048, 'PerImageLocPredMR_at100_iou_0.5': 0.628, 'PerImageLocPredMP_at50_iou_0.5': 0.083, 'PerImageLocPredMR_at50_iou_0.5': 0.572}\n",
      "Step 29000: loss = 1.3320000171661377 (10591.314 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.035, 'PerImageOneHopMR_at100_iou_0.5': 0.478, 'PerImageOneHopMP_at50_iou_0.5': 0.059, 'PerImageOneHopMR_at50_iou_0.5': 0.425, 'PerImageLocPredMP_at100_iou_0.5': 0.057, 'PerImageLocPredMR_at100_iou_0.5': 0.782, 'PerImageLocPredMP_at50_iou_0.5': 0.096, 'PerImageLocPredMR_at50_iou_0.5': 0.691}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.025, 'PerImageOneHopMR_at100_iou_0.5': 0.322, 'PerImageOneHopMP_at50_iou_0.5': 0.043, 'PerImageOneHopMR_at50_iou_0.5': 0.296, 'PerImageLocPredMP_at100_iou_0.5': 0.047, 'PerImageLocPredMR_at100_iou_0.5': 0.629, 'PerImageLocPredMP_at50_iou_0.5': 0.082, 'PerImageLocPredMR_at50_iou_0.5': 0.572}\n",
      "Step 30000: loss = 1.3220000267028809 (11760.319 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.036, 'PerImageOneHopMR_at100_iou_0.5': 0.479, 'PerImageOneHopMP_at50_iou_0.5': 0.06, 'PerImageOneHopMR_at50_iou_0.5': 0.422, 'PerImageLocPredMP_at100_iou_0.5': 0.057, 'PerImageLocPredMR_at100_iou_0.5': 0.782, 'PerImageLocPredMP_at50_iou_0.5': 0.096, 'PerImageLocPredMR_at50_iou_0.5': 0.69}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.025, 'PerImageOneHopMR_at100_iou_0.5': 0.329, 'PerImageOneHopMP_at50_iou_0.5': 0.044, 'PerImageOneHopMR_at50_iou_0.5': 0.298, 'PerImageLocPredMP_at100_iou_0.5': 0.047, 'PerImageLocPredMR_at100_iou_0.5': 0.625, 'PerImageLocPredMP_at50_iou_0.5': 0.082, 'PerImageLocPredMR_at50_iou_0.5': 0.569}\n"
     ]
    }
   ],
   "source": [
    "trainer.train (\n",
    "    max_steps=10000,\n",
    "    train_eval_rate=100, \n",
    "    validation_rate=100, \n",
    "    verbose_rate=1000, \n",
    "    summary_rate=100, \n",
    "    checkpoint_rate=1000, \n",
    "    hyperparams = {\n",
    "        'learning_rate_generator': 1e-6 * batcher.batch_size,\n",
    "\n",
    "        'loss_factor_g_mil_ent': 1.0,\n",
    "        'loss_factor_g_mil_ent_conf': 0.0,\n",
    "        'loss_factor_g_mil_pred': 1.0,\n",
    "        'loss_factor_g_mil_pred_conf': 0.0,\n",
    "        'loss_factor_g_mil_role': 10.0,\n",
    "        'loss_factor_g_mil_box': 10.0,\n",
    "        'loss_factor_g_aux_emb_ent': 0.0,\n",
    "        'loss_factor_g_aux_emb_pred': 0.0,\n",
    "\n",
    "        'confidence_weight_on_role': 0.0,\n",
    "        'grad_clipping': 5.0,\n",
    "        'mil_iou_offset': 0.01,\n",
    "        'dropout_rate_g': 0.0,\n",
    "    },\n",
    "    validation_hyperparams = {\n",
    "        'dropout_rate_g': 0.0,\n",
    "        'confidence_weight_on_role': 0.0\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 31000: loss = 1.4850000143051147 (1164.865 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.035, 'PerImageOneHopMR_at100_iou_0.5': 0.479, 'PerImageOneHopMP_at50_iou_0.5': 0.06, 'PerImageOneHopMR_at50_iou_0.5': 0.426, 'PerImageLocPredMP_at100_iou_0.5': 0.057, 'PerImageLocPredMR_at100_iou_0.5': 0.781, 'PerImageLocPredMP_at50_iou_0.5': 0.096, 'PerImageLocPredMR_at50_iou_0.5': 0.69}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.025, 'PerImageOneHopMR_at100_iou_0.5': 0.325, 'PerImageOneHopMP_at50_iou_0.5': 0.044, 'PerImageOneHopMR_at50_iou_0.5': 0.294, 'PerImageLocPredMP_at100_iou_0.5': 0.048, 'PerImageLocPredMR_at100_iou_0.5': 0.627, 'PerImageLocPredMP_at50_iou_0.5': 0.083, 'PerImageLocPredMR_at50_iou_0.5': 0.565}\n",
      "Step 32000: loss = 1.11899995803833 (2328.772 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.035, 'PerImageOneHopMR_at100_iou_0.5': 0.49, 'PerImageOneHopMP_at50_iou_0.5': 0.059, 'PerImageOneHopMR_at50_iou_0.5': 0.433, 'PerImageLocPredMP_at100_iou_0.5': 0.057, 'PerImageLocPredMR_at100_iou_0.5': 0.785, 'PerImageLocPredMP_at50_iou_0.5': 0.096, 'PerImageLocPredMR_at50_iou_0.5': 0.69}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.025, 'PerImageOneHopMR_at100_iou_0.5': 0.332, 'PerImageOneHopMP_at50_iou_0.5': 0.044, 'PerImageOneHopMR_at50_iou_0.5': 0.304, 'PerImageLocPredMP_at100_iou_0.5': 0.048, 'PerImageLocPredMR_at100_iou_0.5': 0.631, 'PerImageLocPredMP_at50_iou_0.5': 0.083, 'PerImageLocPredMR_at50_iou_0.5': 0.576}\n",
      "Step 33000: loss = 1.2070000171661377 (3475.973 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.035, 'PerImageOneHopMR_at100_iou_0.5': 0.493, 'PerImageOneHopMP_at50_iou_0.5': 0.06, 'PerImageOneHopMR_at50_iou_0.5': 0.441, 'PerImageLocPredMP_at100_iou_0.5': 0.056, 'PerImageLocPredMR_at100_iou_0.5': 0.785, 'PerImageLocPredMP_at50_iou_0.5': 0.095, 'PerImageLocPredMR_at50_iou_0.5': 0.697}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.025, 'PerImageOneHopMR_at100_iou_0.5': 0.332, 'PerImageOneHopMP_at50_iou_0.5': 0.044, 'PerImageOneHopMR_at50_iou_0.5': 0.303, 'PerImageLocPredMP_at100_iou_0.5': 0.048, 'PerImageLocPredMR_at100_iou_0.5': 0.631, 'PerImageLocPredMP_at50_iou_0.5': 0.083, 'PerImageLocPredMR_at50_iou_0.5': 0.573}\n",
      "Step 34000: loss = 1.2769999504089355 (4628.878 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.035, 'PerImageOneHopMR_at100_iou_0.5': 0.493, 'PerImageOneHopMP_at50_iou_0.5': 0.059, 'PerImageOneHopMR_at50_iou_0.5': 0.44, 'PerImageLocPredMP_at100_iou_0.5': 0.056, 'PerImageLocPredMR_at100_iou_0.5': 0.79, 'PerImageLocPredMP_at50_iou_0.5': 0.093, 'PerImageLocPredMR_at50_iou_0.5': 0.696}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.026, 'PerImageOneHopMR_at100_iou_0.5': 0.333, 'PerImageOneHopMP_at50_iou_0.5': 0.045, 'PerImageOneHopMR_at50_iou_0.5': 0.304, 'PerImageLocPredMP_at100_iou_0.5': 0.048, 'PerImageLocPredMR_at100_iou_0.5': 0.631, 'PerImageLocPredMP_at50_iou_0.5': 0.083, 'PerImageLocPredMR_at50_iou_0.5': 0.571}\n",
      "Step 35000: loss = 1.3109999895095825 (5782.102 sec)\n",
      "Training Batch Evaluation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.036, 'PerImageOneHopMR_at100_iou_0.5': 0.497, 'PerImageOneHopMP_at50_iou_0.5': 0.06, 'PerImageOneHopMR_at50_iou_0.5': 0.437, 'PerImageLocPredMP_at100_iou_0.5': 0.056, 'PerImageLocPredMR_at100_iou_0.5': 0.785, 'PerImageLocPredMP_at50_iou_0.5': 0.093, 'PerImageLocPredMR_at50_iou_0.5': 0.685}\n",
      "Validation Results: {'PerImageOneHopMP_at100_iou_0.5': 0.025, 'PerImageOneHopMR_at100_iou_0.5': 0.329, 'PerImageOneHopMP_at50_iou_0.5': 0.044, 'PerImageOneHopMR_at50_iou_0.5': 0.3, 'PerImageLocPredMP_at100_iou_0.5': 0.048, 'PerImageLocPredMR_at100_iou_0.5': 0.63, 'PerImageLocPredMP_at50_iou_0.5': 0.083, 'PerImageLocPredMR_at50_iou_0.5': 0.573}\n"
     ]
    }
   ],
   "source": [
    "trainer.train (\n",
    "    max_steps=5000,\n",
    "    train_eval_rate=100, \n",
    "    validation_rate=100, \n",
    "    verbose_rate=1000, \n",
    "    summary_rate=100, \n",
    "    checkpoint_rate=1000, \n",
    "    hyperparams = {\n",
    "        'learning_rate_generator': 1e-7 * batcher.batch_size,\n",
    "\n",
    "        'loss_factor_g_mil_ent': 1.0,\n",
    "        'loss_factor_g_mil_ent_conf': 0.0,\n",
    "        'loss_factor_g_mil_pred': 1.0,\n",
    "        'loss_factor_g_mil_pred_conf': 0.0,\n",
    "        'loss_factor_g_mil_role': 10.0,\n",
    "        'loss_factor_g_mil_box': 10.0,\n",
    "        'loss_factor_g_aux_emb_ent': 0.0,\n",
    "        'loss_factor_g_aux_emb_pred': 0.0,\n",
    "\n",
    "        'confidence_weight_on_role': 0.0,\n",
    "        'grad_clipping': 5.0,\n",
    "        'mil_iou_offset': 0.01,\n",
    "        'dropout_rate_g': 0.0,\n",
    "    },\n",
    "    validation_hyperparams = {\n",
    "        'dropout_rate_g': 0.0,\n",
    "        'confidence_weight_on_role': 0.0\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('final_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alireza/home_at_filer2/tools/anaconda3/envs/py3tf2/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../../checkpoint/exp_064/ckpt-25000\n"
     ]
    }
   ],
   "source": [
    "load_params(sess, os.path.join(codebase, 'checkpoint', exp_name, 'ckpt-25000'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl = VGGraphLoader(\n",
    "    os.path.join(codebase, 'metadata', 'VG', 'prep', 'stanford', 'sg_stanford_with_duplicates.pkl'),\n",
    "    os.path.join(codebase, 'metadata', 'VG', 'prep', 'stanford', 'word_emb_stanford_2.pkl'),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evaluator = Evaluator({        \n",
    "    'graph_loader': gl,\n",
    "    'proposals': proposals,\n",
    "    'num_proposals': None,\n",
    "    'filter_nonoverlap': True,\n",
    "    'rank_triplet_confidence': False,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = np.asarray(list(set(test_idx) - set(img_no_ent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher_test = GraphBatcher(\n",
    "    gl, 32, proposals,\n",
    "    os.path.join(codebase, 'data', 'VG', 'xfeat_gtbox', 'iresnet_oi_lowprop', 'feats_float32_20x1536.lmdb'), \n",
    "    dim_feats=1536,\n",
    "    seed=1237, \n",
    ")\n",
    "batcher_test.set_subset(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying\n",
      "Batch 1/997 done in 1 seconds. Spent time for read=0.01 (avg 0.01), processing=1.37 (avg 1.37), write=0.00 (avg 0.00) seconds.\n",
      "Batch 101/997 done in 8 seconds. Spent time for read=0.00 (avg 0.01), processing=0.06 (avg 0.08), write=0.00 (avg 0.00) seconds.\n",
      "Batch 201/997 done in 16 seconds. Spent time for read=0.00 (avg 0.01), processing=0.07 (avg 0.07), write=0.00 (avg 0.00) seconds.\n",
      "Batch 301/997 done in 23 seconds. Spent time for read=0.00 (avg 0.01), processing=0.06 (avg 0.07), write=0.00 (avg 0.00) seconds.\n",
      "Batch 401/997 done in 31 seconds. Spent time for read=0.00 (avg 0.01), processing=0.06 (avg 0.07), write=0.00 (avg 0.00) seconds.\n",
      "Batch 501/997 done in 38 seconds. Spent time for read=0.01 (avg 0.01), processing=0.08 (avg 0.07), write=0.00 (avg 0.00) seconds.\n",
      "Batch 601/997 done in 46 seconds. Spent time for read=0.01 (avg 0.01), processing=0.07 (avg 0.07), write=0.00 (avg 0.00) seconds.\n",
      "Batch 701/997 done in 54 seconds. Spent time for read=0.01 (avg 0.01), processing=0.07 (avg 0.07), write=0.00 (avg 0.00) seconds.\n",
      "Batch 801/997 done in 62 seconds. Spent time for read=0.01 (avg 0.01), processing=0.07 (avg 0.07), write=0.00 (avg 0.00) seconds.\n",
      "Batch 901/997 done in 69 seconds. Spent time for read=0.00 (avg 0.01), processing=0.07 (avg 0.07), write=0.00 (avg 0.00) seconds.\n",
      "Batch 997/997 done in 76 seconds. Spent time for read=0.00 (avg 0.01), processing=0.01 (avg 0.07), write=0.00 (avg 0.00) seconds.\n",
      "Done in 76 seconds\n"
     ]
    }
   ],
   "source": [
    "#test_evaluator.reset()\n",
    "deploy(sess, model, batcher_test, test_evaluator, model.eval_ops,\n",
    "    hyperparams={\n",
    "        'dropout_rate_g': 0.0,\n",
    "        'confidence_weight_on_role': 0.0\n",
    "    },\n",
    "    ignore_errors=False,\n",
    "    debug_mode=False,\n",
    "    verbose_rate=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PerImageOneHopMP_at100_iou_0.5': 0.025612059229514372,\n",
       " 'PerImageOneHopMR_at100_iou_0.5': 0.34125216158398747,\n",
       " 'PerImageOneHopMP_at50_iou_0.5': 0.0444924080813151,\n",
       " 'PerImageOneHopMR_at50_iou_0.5': 0.315035548678333,\n",
       " 'PerImageLocPredMP_at100_iou_0.5': 0.04834201279959844,\n",
       " 'PerImageLocPredMR_at100_iou_0.5': 0.646035299673522,\n",
       " 'PerImageLocPredMP_at50_iou_0.5': 0.08310954950432926,\n",
       " 'PerImageLocPredMR_at50_iou_0.5': 0.5913678575900829}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = test_evaluator.evaluate()\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3 w/ Tensorflow 2",
   "language": "python",
   "name": "py3tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
